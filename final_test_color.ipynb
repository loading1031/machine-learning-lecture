{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: torch.Size([32, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Python Garbage Collector\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import kagglehub\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터 경로 설정\n",
    "save_path = \"/Volumes/Extreme SSD/kaggle/datasets/tempusme/faces-emore-112x112/faces_emore_112x112_folders\"\n",
    "\n",
    "# Custom Dataset 정의\n",
    "class KaggleDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, original_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        # 하위 폴더까지 재귀적으로 모든 이미지 파일 경로 수집\n",
    "        self.image_paths = []\n",
    "        for root, _, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(('.jpg', '.png')):  # 이미지 파일 필터링\n",
    "                    self.image_paths.append(os.path.join(root, file))\n",
    "        self.transform = transform\n",
    "        self.original_transform = original_transform or transforms.ToTensor()  # 기본 변환 설정\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        original_image = Image.open(img_path)  # 이미지 로드\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(original_image)\n",
    "\n",
    "        # 원본 이미지를 텐서로 변환\n",
    "        original_image = self.original_transform(original_image)\n",
    "        \n",
    "        return image, original_image\n",
    "\n",
    "# Transform 정의 (28x28로 크기 조정)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 이미지 크기를 28x28로 조정\n",
    "    transforms.ToTensor(),       # 텐서로 변환\n",
    "])\n",
    "\n",
    "original_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 원본 이미지는 크기 변경 없이 텐서로만 변환\n",
    "])\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = KaggleDataset(\n",
    "    data_dir=save_path, \n",
    "    transform=transform,\n",
    "    original_transform=original_transform  # 원본 이미지\n",
    "    )\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 데이터 확인 (테스트)\n",
    "for batch_idx, (data, _) in enumerate(data_loader):\n",
    "    print(f\"Batch {batch_idx + 1}: {data.size()}\")\n",
    "    if batch_idx == 0:  # 첫 번째 배치만 출력\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# 타임시드 설정\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Sub-pixel Convolution Layer 정의\n",
    "class SubPixelConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upscale_factor):\n",
    "        super(SubPixelConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * (upscale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pixel_shuffle(self.conv(x))\n",
    "\n",
    "# Generator (ESPCN)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            SubPixelConv2d(32, 3, upscale_factor)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# 데이터 준비\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 생성\n",
    "model_a = Generator(upscale_factor=2).to(device)  # A는 upscale_factor=2\n",
    "model_b = Generator(upscale_factor=4).to(device)  # B는 upscale_factor=4\n",
    "\n",
    "optimizer_a = optim.Adam(model_a.parameters(), lr=1e-4)\n",
    "optimizer_b = optim.Adam(model_b.parameters(), lr=1e-4)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# # 모델 요약 출력\n",
    "# summary(model_a, input_size=(3, 28, 28))  # (채널, 높이, 너비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting stage: 28x28\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# 학습\n",
    "epoch_num = 10\n",
    "initial_resolution = 28\n",
    "next_resolution = initial_resolution\n",
    "final_resolution = 128\n",
    "prev_output_a = None  # 이전 단계의 A 출력\n",
    "prev_output_b = None  # 이전 단계의 B 출력\n",
    "max_upscale_factor = 4  # A, B의 upscale_factor 최소 공배수\n",
    "\n",
    "while next_resolution <= final_resolution:\n",
    "    print(f\"Starting stage: {next_resolution}x{next_resolution}\")\n",
    "\n",
    "    current_prev_output = []  # 이번 단계의 출력 리스트\n",
    "\n",
    "    for epoch in range(epoch_num):  # 각 단계에서 3 에포크 학습\n",
    "        for batch_idx, (data, original_data) in enumerate(data_loader):\n",
    "            # 데이터 준비\n",
    "            data = data.to(device)\n",
    "            original_data = original_data.to(device)  # 원본 이미지\n",
    "\n",
    "            if next_resolution == initial_resolution:\n",
    "                # 첫 단계에서는 원본 데이터에서 저해상도 생성\n",
    "                current_resolution = next_resolution // 4\n",
    "                low_res = nn.functional.interpolate(data, size=(current_resolution, current_resolution), mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                # 이후 단계에서는 이전 출력 이미지를 가져옴\n",
    "                if batch_idx < len(prev_output):\n",
    "                    low_res = prev_output[batch_idx].to(device)\n",
    "                else:\n",
    "                    raise IndexError(\"Batch index out of range for previous outputs.\")\n",
    "\n",
    "            # 모델 A와 B의 출력\n",
    "            output_a_step1 = model_a(low_res)\n",
    "            output_a = model_a(output_a_step1)\n",
    "            output_b = model_b(low_res)\n",
    "\n",
    "            # 보조값 C 생성\n",
    "            target_resolution = output_a.shape[-2:]\n",
    "            high_res_c = nn.functional.interpolate(data, size=target_resolution, mode='bilinear', align_corners=False)\n",
    "\n",
    "            # 평균값 계산\n",
    "            avg_output = data if(next_resolution == initial_resolution) else (output_a + output_b + high_res_c) / 3\n",
    "\n",
    "            # 손실 계산\n",
    "            loss_a = nn.MSELoss()(output_a, avg_output)\n",
    "            loss_b = nn.MSELoss()(output_b, avg_output)\n",
    "            total_loss = loss_a + loss_b\n",
    "\n",
    "            # 모델 학습\n",
    "            optimizer_a.zero_grad()\n",
    "            optimizer_b.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer_a.step()\n",
    "            optimizer_b.step()\n",
    "\n",
    "            if epoch == epoch_num-1:\n",
    "            # 다음 단계 출력을 저장\n",
    "                if next_resolution * 4 < final_resolution :\n",
    "                    if batch_idx < len(current_prev_output):\n",
    "                        current_prev_output[batch_idx] = avg_output.detach()\n",
    "                    else:\n",
    "                        current_prev_output.append(data.detach())\n",
    "                else:\n",
    "                    # 마지막 단계라면 리스트를 비움\n",
    "                    current_prev_output.clear()\n",
    "\n",
    "        # 출력\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{current_time}] Epoch [{epoch+1}/{epoch_num}], Loss A: {loss_a.item():.4f}, Loss B: {loss_b.item():.4f}\")\n",
    "\n",
    "    # 학습 마지막 에포크에서 출력\n",
    "    with torch.no_grad():\n",
    "        print(f\"Displaying results for resolution: {next_resolution}x{next_resolution}\")\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        for i in range(5):  # 5개의 샘플 출력\n",
    "            # 저해상도 A\n",
    "            plt.subplot(5, 5, i + 1)\n",
    "            plt.imshow(low_res[i].squeeze().cpu().numpy())\n",
    "            plt.title(f\"Low Res A ({target_resolution[0] // max_upscale_factor}x{target_resolution[0] // max_upscale_factor})\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # A의 결과\n",
    "            plt.subplot(5, 5, i + 6)\n",
    "            plt.imshow(output_a[i].squeeze().cpu().numpy())\n",
    "            plt.title(f\"Model A ({target_resolution[0]}x{target_resolution[1]})\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # B의 결과\n",
    "            plt.subplot(5, 5, i + 11)\n",
    "            plt.imshow(output_b[i].squeeze().cpu().numpy())\n",
    "            plt.title(f\"Model B ({target_resolution[0]}x{target_resolution[1]})\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 보조값 C\n",
    "            plt.subplot(5, 5, i + 16)\n",
    "            plt.imshow(high_res_c[i].squeeze().cpu().numpy())\n",
    "            plt.title(\"Interpolate (C)\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 평균값\n",
    "            plt.subplot(5, 5, i + 21)\n",
    "            plt.imshow(avg_output[i].squeeze().cpu().numpy())\n",
    "            plt.title(\"Average (A+B+C)\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 원본 이미지\n",
    "            plt.subplot(5, 6, i * 6 + 1)\n",
    "            plt.imshow(original_data[i].squeeze().cpu().numpy())\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 에포크 종료 후 메모리 캐시 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()  # CPU 메모리 정리\n",
    "    \n",
    "    # 각 단계가 끝나면 A와 B의 출력 이미지를 다음 단계 입력으로 저장\n",
    "    prev_output = current_prev_output  # 다음 단계의 저해상도로 사용\n",
    "\n",
    "    # 다음 단계로 해상도 증가\n",
    "    next_resolution *= max_upscale_factor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVDclassification-based-on-ECG-signals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

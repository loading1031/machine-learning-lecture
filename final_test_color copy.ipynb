{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 5822653개의 이미지 파일이 탐색되었습니다.\n",
      "Batch 1: 변환된 이미지 크기: torch.Size([32, 3, 28, 28]), 원본 이미지 크기: torch.Size([32, 3, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Python Garbage Collector\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Custom Dataset 정의\n",
    "class ZipDataset(Dataset):\n",
    "    def __init__(self, zip_file, transform=None, original_transform=None):\n",
    "        self.zip_file = zipfile.ZipFile(zip_file, 'r')  # ZIP 파일 오픈\n",
    "        self.image_names = [\n",
    "            name for name in self.zip_file.namelist() if name.endswith(('.jpg', '.png'))\n",
    "        ]  # 이미지 파일만 필터링\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "        self.original_transform = original_transform or transforms.ToTensor()  # 기본 변환 설정\n",
    "        \n",
    "        print(f\"총 {len(self.image_names)}개의 이미지 파일이 탐색되었습니다.\")  # 디버깅용 출력\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_data = self.zip_file.read(img_name)  # ZIP 내부의 이미지 파일 읽기\n",
    "        original_image = Image.open(BytesIO(img_data))  # Bytes 데이터를 PIL 이미지로 변환\n",
    "\n",
    "        # 원본 이미지를 변환 없이 저장\n",
    "        if self.original_transform:\n",
    "            original_image_tensor = self.original_transform(original_image)\n",
    "        else:\n",
    "            original_image_tensor = original_image\n",
    "\n",
    "        # 변환된 이미지를 생성\n",
    "        if self.transform:\n",
    "            image = self.transform(original_image)\n",
    "        else:\n",
    "            image = original_image_tensor\n",
    "\n",
    "        return image, original_image_tensor  # 변환된 이미지와 원본 텐서를 반환\n",
    "\n",
    "# Transform 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 이미지 크기를 28x28로 조정\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "original_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 원본 이미지는 크기 변경 없이 텐서로만 변환\n",
    "])\n",
    "\n",
    "# 압축 파일 경로\n",
    "zip_file_path = r\"C:\\Users\\seongmun\\Downloads\\archive.zip\"\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = ZipDataset(zip_file=zip_file_path, transform=transform, original_transform=original_transform)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 데이터 확인 (테스트)\n",
    "for batch_idx, (data, original) in enumerate(data_loader):\n",
    "    print(f\"Batch {batch_idx + 1}: 변환된 이미지 크기: {data.size()}, 원본 이미지 크기: {original.size()}\")\n",
    "    if batch_idx == 0:  # 첫 번째 배치만 출력\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 타임시드 설정\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Sub-pixel Convolution Layer 정의\n",
    "class SubPixelConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upscale_factor):\n",
    "        super(SubPixelConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * (upscale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pixel_shuffle(self.conv(x))\n",
    "\n",
    "# Generator (ESPCN)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            SubPixelConv2d(32, 3, upscale_factor)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# 데이터 준비\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 생성\n",
    "model_a = Generator(upscale_factor=2).to(device)  # A는 upscale_factor=2\n",
    "model_b = Generator(upscale_factor=4).to(device)  # B는 upscale_factor=4\n",
    "\n",
    "optimizer_a = optim.Adam(model_a.parameters(), lr=1e-4)\n",
    "optimizer_b = optim.Adam(model_b.parameters(), lr=1e-4)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# # 모델 요약 출력\n",
    "# summary(model_a, input_size=(3, 28, 28))  # (채널, 높이, 너비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting stage: Intermediate 7x7 -> 28x28\n",
      "[2024-12-14 19:32:14] Epoch [1/3], loss_a: 0.0059, loss_b: 0.0058.\n",
      "Models saved: model_checkpoints\\model_a_epoch_1.pth and model_checkpoints\\model_b_epoch_1.pth\n",
      "[2024-12-14 21:56:24] Epoch [2/3], loss_a: 0.0058, loss_b: 0.0057.\n",
      "Models saved: model_checkpoints\\model_a_epoch_2.pth and model_checkpoints\\model_b_epoch_2.pth\n",
      "[2024-12-15 00:35:19] Epoch [3/3], loss_a: 0.0056, loss_b: 0.0056.\n",
      "Models saved: model_checkpoints\\model_a_epoch_3.pth and model_checkpoints\\model_b_epoch_3.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# 학습\n",
    "epoch_num = 3\n",
    "initial_resolution = 28\n",
    "intermediate_resolution = 7\n",
    "final_resolution = 112\n",
    "\n",
    "print(f\"Starting stage: Intermediate {intermediate_resolution}x{intermediate_resolution} -> {initial_resolution}x{initial_resolution}\")\n",
    "\n",
    "import os\n",
    "\n",
    "# 저장할 디렉토리 경로 설정\n",
    "save_dir = \"model_checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "for epoch in range(epoch_num):  # 각 단계에서 3 에포크 학습\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        # 데이터 준비\n",
    "        data = data.to(device)\n",
    "\n",
    "        # 첫 단계: 28x28 -> 7x7\n",
    "        low_res_intermediate = nn.functional.interpolate(data, size=(intermediate_resolution, intermediate_resolution), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # 두 번째 단계: 7x7 -> 28x28\n",
    "        output_a_step1 = model_a(low_res_intermediate)  # 첫 번째 업스케일(14x14)\n",
    "        output_a = model_a(output_a_step1)  # 두 번째 업스케일(28x28)\n",
    "\n",
    "        output_b = model_b(low_res_intermediate)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss_a = nn.MSELoss()(output_a, data)\n",
    "        loss_b = nn.MSELoss()(output_b, data)\n",
    "        total_loss = loss_a + loss_b\n",
    "\n",
    "        # 모델 학습\n",
    "        optimizer_a.zero_grad()\n",
    "        optimizer_b.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_a.step()\n",
    "        optimizer_b.step()\n",
    "\n",
    "    # 출력\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{current_time}] Epoch [{epoch + 1}/{epoch_num}], loss_a: {loss_a.item():.4f}, loss_b: {loss_b.item():.4f}.\")\n",
    "\n",
    "    # 모델 저장\n",
    "    checkpoint_path_a = os.path.join(save_dir, f\"model_a_epoch_{epoch + 1}.pth\")\n",
    "    checkpoint_path_b = os.path.join(save_dir, f\"model_b_epoch_{epoch + 1}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model_a.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_a.state_dict(),\n",
    "        'loss': total_loss.item(),\n",
    "    }, checkpoint_path_a)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model_b.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_b.state_dict(),\n",
    "        'loss': total_loss.item(),\n",
    "    }, checkpoint_path_b)\n",
    "\n",
    "    print(f\"Models saved: {checkpoint_path_a} and {checkpoint_path_b}\")\n",
    "\n",
    "# 에포크 종료 후 메모리 캐시 정리\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting stage: Intermediate 28x28 -> 112x112\n",
      "[2024-12-15 16:58:27] Epoch [1/3], Loss A: 0.0000, Loss B: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting stage: Intermediate {initial_resolution}x{initial_resolution} -> {final_resolution}x{final_resolution}\")\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_idx, (data, original_data) in enumerate(data_loader):\n",
    "        # 데이터 준비\n",
    "        data = data.to(device)\n",
    "        original_data = original_data.to(device)\n",
    "\n",
    "        # 두 번째 단계: 28x28 -> 112x112 (Model A는 upscale factor가 2이므로 두 번 적용)\n",
    "        output_a_step1 = model_a(data)  # 첫 번째 업스케일\n",
    "        output_a = model_a(output_a_step1)  # 두 번째 업스케일\n",
    "        output_b = model_b(data)\n",
    "\n",
    "        # 보조값 C 생성\n",
    "        high_res_c = nn.functional.interpolate(data, size=(final_resolution, final_resolution), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # 평균값 계산\n",
    "        avg_output = (output_a + output_b + high_res_c) / 3\n",
    "\n",
    "        # 손실 계산\n",
    "        loss_a = nn.MSELoss()(output_a, avg_output)\n",
    "        loss_b = nn.MSELoss()(output_b, avg_output)\n",
    "        total_loss = loss_a + loss_b\n",
    "\n",
    "        # 모델 학습\n",
    "        optimizer_a.zero_grad()\n",
    "        optimizer_b.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_a.step()\n",
    "        optimizer_b.step()\n",
    "\n",
    "    # 출력\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{current_time}] Epoch [{epoch + 1}/{epoch_num}], Loss A: {loss_a.item():.4f}, Loss B: {loss_b.item():.4f}\")\n",
    "\n",
    "# 학습 마지막 에포크에서 출력\n",
    "with torch.no_grad():\n",
    "    print(f\"Displaying results for resolution: {final_resolution}x{final_resolution}\")\n",
    "    plt.figure(figsize=(20, 25))  # 더 넓은 공간 설정\n",
    "    for i in range(5):  # 5개의 샘플 출력\n",
    "        # 중간 저해상도\n",
    "        plt.subplot(5, 5, i * 5 + 1)  # 각 행의 첫 번째 서브플롯\n",
    "        plt.imshow(data[i].squeeze().cpu().numpy())\n",
    "        plt.title(f\"Input ({initial_resolution}x{initial_resolution})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # A의 결과\n",
    "        plt.subplot(5, 5, i * 5 + 2)  # 두 번째 서브플롯\n",
    "        plt.imshow(output_a[i].squeeze().cpu().numpy())\n",
    "        plt.title(f\"Model A ({final_resolution}x{final_resolution})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # B의 결과\n",
    "        plt.subplot(5, 5, i * 5 + 3)  # 세 번째 서브플롯\n",
    "        plt.imshow(output_b[i].squeeze().cpu().numpy())\n",
    "        plt.title(f\"Model B ({final_resolution}x{final_resolution})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 보조값 C\n",
    "        plt.subplot(5, 5, i * 5 + 4)  # 네 번째 서브플롯\n",
    "        plt.imshow(high_res_c[i].squeeze().cpu().numpy())\n",
    "        plt.title(\"Interpolate (C)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 평균값\n",
    "        plt.subplot(5, 5, i * 5 + 5)  # 다섯 번째 서브플롯\n",
    "        plt.imshow(avg_output[i].squeeze().cpu().numpy())\n",
    "        plt.title(\"Average (A+B+C)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "         # 112x112원본 \n",
    "        plt.subplot(5, 5, i * 5 + 5)  # 다섯 번째 서브플롯\n",
    "        plt.imshow(original_data[i].squeeze().cpu().numpy())\n",
    "        plt.title(\"Original 112x112\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    \n",
    "    # 학습 마지막 에포크 손실 계산 및 출력\n",
    "    final_loss = nn.MSELoss()(avg_output, original_data)\n",
    "    print(f\"Final epoch loss between avg_output and original_data: {final_loss.item():.4f}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 에포크 종료 후 메모리 캐시 정리\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  # CPU 메모리 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "checkpoint_path_a = os.path.join(save_dir, f\"model_a_112x112.pth\")\n",
    "checkpoint_path_b = os.path.join(save_dir, f\"model_b_112x112.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': model_a.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_a.state_dict(),\n",
    "    'loss': total_loss.item(),\n",
    "}, checkpoint_path_a)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_b.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_b.state_dict(),\n",
    "    'loss': total_loss.item(),\n",
    "}, checkpoint_path_b)\n",
    "\n",
    "print(f\"Models saved: {checkpoint_path_a} and {checkpoint_path_b}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
